{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE888 Assignment 2 for Demo\n",
    "\n",
    "This code is written to demonstarte data analysis made for ce888 assignment 2.\n",
    "\n",
    "**Author**          : Tomoko Ayakawa<br> \n",
    "**Created on**      : 29 March 2019<br> \n",
    "**Last modified on**: 18 April 2019<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open source libraries\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# import original libraries\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "#import utility as UTL\n",
    "import assignment2_main as MAIN2\n",
    "from conf import myVariables as VAR\n",
    "import load_data as DATA\n",
    "import preprocess as PREP\n",
    "import autoencoder as AE\n",
    "import mlp as MLP\n",
    "import grid_search as GS\n",
    "\n",
    "\n",
    "#import histogram as HST\n",
    "#import correlation as CRRL\n",
    "import pca as PCA\n",
    "import classifier as CLS\n",
    "#import feature_importance as IMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "Load data from **data** directory.<br>\n",
    "\n",
    "### 1-1. Select the data to load\n",
    "> 0. Human Activity\n",
    "1. Spam\n",
    "2. Phishing\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_list={0: \"human activity\", 1: \"spam\", 2: \"phishing\"}\n",
    "data_id=int(input(data_list))\n",
    "\n",
    "col_names, features_df, targets_df, data_df, pic_file=DATA.load_data(data_id=data_id)\n",
    "unique_labels=DATA.verify_data(data_df, targets_df, dispaly_range=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Obtain the small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, classes=PREP.get_small_data(features_df, targets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Pre-process the data\n",
    "Fit the scaler and transform the data.<br>\n",
    "When the scaler ID is not specified, MinMaxScaler will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl, features_nrm=PREP.pre_processing(features, display_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y=features_nrm, classes\n",
    "X_tr, X_te, y_tr, y_te=PREP.split_data(features_nrm, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build an Autoencoder\n",
    "### 4-1. Define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_layers, mode, act, opt, loss, dropout, \\\n",
    "    epochs, verbose, summary_display=AE.get_parameters(data_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, histories=AE.autoencoder(X, layers=ae_layers, mode=mode, act=act, opt=opt, \n",
    "                                 loss=loss, dropout=dropout, epochs=epochs, \n",
    "                                 verbose=verbose, summary_display=summary_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. Display the training loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE.plot_ae_loss_history(histories, mode, pic_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4. Extract features from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_cmp=encoder.predict(features_nrm)\n",
    "X_tr_cmp=encoder.predict(X_tr)\n",
    "X_te_cmp=encoder.predict(X_te)\n",
    "\n",
    "print(\"The number of compressed features:\", len(X_all_cmp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build a discriminative neural network\n",
    "### 5-1. Define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune, h_num, h_act, out_act, opt, loss, epochs, val_rate, \\\n",
    "    verbose, summary_display=MLP.get_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. Train the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=ae_layers[-1]\n",
    "n=len(np.unique(y))\n",
    "\n",
    "model=MLP.build_mlp(encoder, num_in=k, num_out=n, \\\n",
    "            finetune=finetune, h_num=h_num, h_act=h_act, \\\n",
    "            out_act=out_act, opt=opt, loss=loss, \\\n",
    "            summary_display=summary_display)\n",
    "histories=MLP.train_mlp(X, y, model, epochs=epochs, \\\n",
    "            val_rate=val_rate, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3. Display the training loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.plot_mlp_loss_history(histories, pic_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Grid Search for optimal parameter\n",
    "### 6-1. Define the parameters\n",
    "The codes and markdown below are originally written by the author for the assignment for CE802 which was submitted to the CSEE Department on 16 January 2019.<br><br>\n",
    "Major parameters to be tuned are:\n",
    "\n",
    "\n",
    "|parameter               |default    |description                                              |\n",
    "|------------------------|-----------|---------------------------------------------------------|\n",
    "|hidden_layer_sizes      |(100,)     |i-th element: numb of neurons in the i-th hidden layer   |\n",
    "|activation              |\"relu\"     |activation function                                      |\n",
    "|solver                  |\"adam\"     |weight optimasation                                      |\n",
    "|alpha                   |0.0001     |regularization parameter                                 |\n",
    "|learning_rate_init      |0.001      |step-size in weights update (solver=’sgd’ or ‘adam’)     |\n",
    "|max_iter                |200        |max num of iterations                                    |\n",
    "|momentum                |0.9        |momentum for gradient descent update (range (0, 1), solver=’sgd’|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act, h_num, max_itr, lr, mmt, alpha, solver, splits=GS.get_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid, clf=GS.parameter_grid(activation=act, \\\n",
    "                           alpha=alpha, hidden_layer_sizes=(h_num,), \\\n",
    "                           max_iter=max_itr, learning_rate_init=lr, \\\n",
    "                           momentum=mmt, solver=solver)\n",
    "if param_grid!=1: GS.grid_search(X_all_cmp, y, clf, param_grid, grid_splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n",
    "### 6-1. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs, fscores=MLP.cross_validation(model, X, y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. Train, predict and evaluate the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=MLP.evaluation(model, X_tr, y_tr, X_te, y_te, pic_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with other thechniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ae_layers[-1]==3:\n",
    "    PCA.pca(X_all_cmp, y, unique_labels, \"Compressed by autoencoder\", PCA=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3. Compare with other procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"%s_Decision_Tree (%d)\" % (pic_file, len(X))\n",
    "y_te, pred, clf=CLS.train (X_tr, y_tr, 0, 0)\n",
    "CLS.plot_confusion_matrix(y_te, pred, unique_labels, pic_file, title, \"Decision_Tree\")\n",
    "\n",
    "from sklearn import metrics\n",
    "print (\"\\n< Accuracy> %f\" % metrics.accuracy_score(y_te, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=\"%s_Naive Bayes (%d)\" % (pic_file, len(X))\n",
    "y_te, pred, clf=CLS.train(X_tr, y_tr, 1, 0)\n",
    "CLS.plot_confusion_matrix(y_te, pred, unique_labels, pic_file, title, \"Naive Bayes\")\n",
    "\n",
    "print (\"\\n< Accuracy> %f\" % metrics.accuracy_score(y_te, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title=\"%s_SVM (%d)\" % (pic_file, len(X))\n",
    "y_te, pred, clf= CLS.train(X_tr, y_tr, 2, data_id)\n",
    "CLS.plot_confusion_matrix(y_te, pred, unique_labels, pic_file, title, \"SVM\")\n",
    "\n",
    "print (\"\\n< Accuracy> %f\" % metrics.accuracy_score(y_te, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
